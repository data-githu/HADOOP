■ 하둡 분산 파일 시스템 명령어 15가지

하둡 분산 파일 시스템 명령어 001. ls 명령어
"지정된 디렉토리에 있는 파일의 정보를 출력"
예 : 
$ cd
$ ls -l emp2.csv
$ hadoop fs -put /home/scott/emp2.csv /user/scott/emp3.csv
$ hadoop fs -ls /user/scott/emp3.csv
	
*하둡 파일 시스템에 올린 파일들을 웹페이지로 확인하는 방법
$ export DISPLAY=192.168.19.31:0.0
$ xclock
$ firefox centos:50070

하둡 분산 파일 시스템 명령어 002. lsr 명령어
"현재 디렉토리 뿐만 아니라 하위 디렉토리까지 조회하는 명령어"
예:
$ hadoop fs -lsr /user/
	
문제277. 하둡 파일 시스템의 /root 밑에 있는 모든 하위 디렉토리를 조회하시오!
$ hadoop fs -lsr

하둡 분산 파일 시스템 명령어 003. du 명령어
"파일의 용량을 확인하는 명령어"
예:
$ hadoop fs -du
	
하둡 분산 파일 시스템 명령어 004. dus 명령어
 "파일의 전체 합계 용량을 확인하는 명령어"

예제: $ hadoop  fs   -dus
	
하둡 분산 파일 시스템 명령어 005. cat 명령어
"지정된 파일의 내용을 확인하는 명령어"
예:
$ hadoop fs -cat /user/scott/emp3.csv
	
하둡 분산 파일 시스템 명령어 006. text 명령어
"지정된 파일의 내용을 화면에 출력하는 명령어"
예:
$ hadoop fs -text /user/scott/emp3.csv
	
문제278. 하둡의 파일 시스템의 리눅스 /home/scott 밑에 Case.csv 를 /user/scott 밑에 case3.csv 로 올리시오.
$ hadoop fs -put /home/scott/Case.csv /user/scott/case3.csv

문제279. 하둡 파일 시스템에 올린 case3.csv 의 내용을 조회하시오!
$ hadoop  fs  -cat  /user/scott/case3.csv 
$ hadoop  fs  -text  /user/scott/case3.csv 

하둡 분산 파일 시스템 명령어 007. mkdir 명령어
"디렉토리를 생성하는 명령어"
예 :
$ hadoop fs -mkdir /user/scott/test
	
문제280. 위에서 만든 test 디렉토리가 잘 생성되었는지 확인하시오!
$ hadoop fs -ls 


하둡 분산 파일 시스템 명령어 008. put 명령어
"하둡 파일 시스템에 파일을 올리는 명령어"
예:
$ hadoop fs -put /home/scott/emp2.csv /user/scott/test/emp5.csv

문제281. 앞으로는 test 디렉토리에 데이터를 올리고 관리하기 위해서 리눅스에 있는 /home/scott 밑에 있는 emp2.csv 를  /user/scott/test 에 emp2.csv로 올리시오.
$ hadoop fs -put /home/scott/emp2.csv /user/scott/test/emp2.csv 

하둡 분산 파일 시스템 명령어 009. get 명령어
"하둡 파일 시스템에 올린 파일을 리눅스 디렉토리로 내리는 명령어"
예:
$ cd
$ rm emp2.csv
$ ls -l emp2.csv
$ hadoop fs -get /user/scott/test/emp5.csv /home/scott/emp2.csv
	
하둡 분산 파일 시스템 명령어 010. rm명령어
"하둡 파일 시스템에 있는 파일을 지우는 명령어"
예: 
$ hadoop fs -lsr /user/
$ hadoop fs -rm /user/scott/emp3.csv
Deleted hdfs://localhost:9000/user/scott/emp3.csv

문제282. 리눅스에 /home/scott 밑에 있는 emp2.csv 를 하둡에 /user/scott 밑에 emp3.csv 로 올리시오.
$ hadoop fs -put /home/scott/emp2.csv /user/scott/emp3.csv

하둡 분산 파일 시스템 명령어 011. rmr명령어
"하둡 파일 시스템의 디렉토리를 삭제하는 명령어"
예 :
$ hadoop fs -rmr /user/scott/test
Deleted hdfs://localhost:9000/user/scott/test

문제283. 코로나 데이터 중 감염자 정보 중에 성별 데이터가 있는 csv 파일을 하둡 파일 시스템에 /user/scott 밑에 올리시오.
$ hadoop fs -put /media/sf_data TimeGende.csv /user/scott/TimeGende.csv

하둡 분산 파일 시스템 명령어 012. grep명령어
"파일에서 특정 문자의 행의 데이터를 검색하는 명령어"
예:
$ hadoop fs -put /home/scott/emp2.csv /user/scott/emp7.csv
$ hadoop fs -cat /user/scott/emp7.csv | grep -i 'salesman'

문제284. 하둡 파일 시스템에 올린 코로나 데이터인 timegender.csv파일을 cat으로 여시오!
$ hadoop fs -cat /user/scott/TimeGender.csv

문제285. 하둡 파일 시스템에 올린 코로나 데이터인 TimeGender.csv 파일에서 남자가 모두 몇명인지 확인하시오!
$ hadoop fs -cat /user/scott/TimeGender.csv | grep -i 'male' | wc -l

문제286. 판다를 이용해서 원형그래프를 그리시오.
	1. 리눅스 /home/scott/ 밑에 있는 emp2.csv 를 판다스로 로드해서 emp2.csv를 emp데이터 프레임으로 만들어서 프린트 하시오!
	
	import pandas as pd
	emp=pd.read_csv("/home/scott/emp2.csv",header=None)
	print(emp)
	
	2. 직업과 직업별 인원수를 출력하시오!
	result=emp[2].value_counts()
	print(result)

	3. 직업과 직업별 인원수를 막대 그래프로 그리시오.
	result.plot(kind='bar')
	
 ※ kind 옵션
 'pie' 원형 그래프/ 'line' 선그래프/ 'bar' 수직 막대그래프/ 'kde' 커널 밀도 그래프  /'barh' 수평 막대그래프/'area' 면적 그래프/ 'his' 히스토그램 그래프/ 'scatter' 산점도 그래프/ 'box' 박스(사분위수) 그래프/ 'hexbin' 고밀도 산점도 그래프

문제287. 판다스로 직업, 직업별 토탈월급을 출력하시오!
import pandas as pd
emp=pd.read_csv("/home/scott/emp2.csv")
result=emp.groupby('job')['sal'].sum()
print(result)

하둡 분산 파일 시스템 명령어 013. awk명령어
"특정 컬럼을 검색하는 명령어"

예: 하둡 파일 시스템에 올린 emp3.csv 파일에서 SCOTT인 사원의 이름과 월급을 조회하시오.
$ hadoop fs -cat /user/scott/emp3.csv | grep -i 'scott' | awk -F "," '{print $2, $6}'

설명 : 데이터가 콤마(,) 로 구분되어 있으면 awk 에 -F 옵션을 써서 "," 로 구분되어있다는 것을 알려줘야합니다.

하둡 분산 파일 시스템 명령어 014. count 명령어
"지정된 디렉토리의 파일의 개수를 확인하는 명령어"

예:
$ hadoop fs -lsr /user/scott
$ hadoop fs -count /user/scott

하둡 분산 파일 시스템 명령어 015. 하둡 파일 시스템 명령어 매뉴얼 보는 방법
$ hadoop fs -help